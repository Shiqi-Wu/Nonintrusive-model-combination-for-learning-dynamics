{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".CodeMirror{\n",
       "font-size: 22px;\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style type='text/css'>\n",
    ".CodeMirror{\n",
    "font-size: 22px;\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from Cardiac_electrophysiology import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 3, 51, 51)\n",
      "(100, 51, 51)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "s = np.load('s_50_1000.npy')\n",
    "v = np.load('v_50_1000.npy')\n",
    "\n",
    "print(np.shape(s))\n",
    "print(np.shape(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the input tensor\n",
    "DataModel = CE_DataModel()\n",
    "x1 = np.linspace(0,1,51)\n",
    "t = np.linspace(0,10,100)\n",
    "u_t = np.logical_and(t >= 3, t <= 4)\n",
    "x_mesh = DataModel.dx(x1,x1)\n",
    "u_x_mesh = (x_mesh < 0.03)\n",
    "u = u_t[:,np.newaxis,np.newaxis] * u_x_mesh[np.newaxis,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the dataset\n",
    "s_train = s[:,:,-22:,-22:]\n",
    "v_train = v[:,-22:,-22:]\n",
    "\n",
    "# Build v_xx\n",
    "dlt_x = x1[1]-x1[0]\n",
    "v_train_xx = np.zeros(np.shape(v_train))\n",
    "for i in range(1, np.shape(v_train)[2]-1):\n",
    "    v_train_xx[:,:,i] = (v_train[:,:,i-1] + v_train[:,:,i+1] - 2*v_train[:,:,i])/dlt_x**2\n",
    "v_train_xx = v_train_xx[:,1:-1,1:-1]\n",
    "\n",
    "# Build v_yy\n",
    "dlt_y = x1[1]-x1[0]\n",
    "v_train_yy = np.zeros(np.shape(v_train))\n",
    "for i in range(1, np.shape(v_train)[1]-1):\n",
    "    v_train_yy[:,i,:] = (v_train[:,i-1,:] + v_train[:,i+1,:] - 2*v_train[:,i,:])/dlt_y**2\n",
    "v_train_yy = v_train_yy[:,1:-1,1:-1]\n",
    "\n",
    "# Select v_train, s_train\n",
    "v_train = v_train[:,1:-1,1:-1]\n",
    "s_train = s_train[:,:,1:-1,1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39600, 4)\n",
      "(39600, 4)\n"
     ]
    }
   ],
   "source": [
    "# Build training data\n",
    "v1 = np.reshape(v_train[1:,:,:],(-1, 1))\n",
    "v0 = np.reshape(v_train[:-1,:,:],(-1,1))\n",
    "lacev_x1 = np.reshape(v_train_xx[1:,:,:],(-1,1))\n",
    "lacev_x0 = np.reshape(v_train_xx[:-1,:,:],(-1,1))\n",
    "lacev_y1 = np.reshape(v_train_yy[1:,:,:],(-1,1))\n",
    "lacev_y0 = np.reshape(v_train_yy[:-1,:,:],(-1,1))\n",
    "\n",
    "lace_train = np.concatenate((lacev_x0,lacev_x1,lacev_y0,lacev_y1),axis=1)\n",
    "\n",
    "m1 = np.reshape(s_train[1:,0,:,:],(-1,1))\n",
    "m0 = np.reshape(s_train[:-1,0,:,:],(-1,1))\n",
    "n1 = np.reshape(s_train[1:,1,:,:],(-1,1))\n",
    "n0 = np.reshape(s_train[:-1,1,:,:],(-1,1))\n",
    "h1 = np.reshape(s_train[1:,2,:,:],(-1,1))\n",
    "h0 = np.reshape(s_train[:-1,2,:,:],(-1,1))\n",
    "\n",
    "x_train = np.concatenate((v0,m0,n0,h0),axis=1)\n",
    "y_train = np.concatenate((v1,m1,n1,h1),axis=1)\n",
    "# y_train = np.zeros((len(v1),4))\n",
    "# y_train[:,0],y_train[:,1],y_train[:,2],y_train[:,3] = v1,m1,n1,h1\n",
    "# x_train = np.zeros((len(v0),4))\n",
    "# x_train[:,0],x_train[:,1],x_train[:,2],x_train[:,3] = v0,m0,n0,h0\n",
    "\n",
    "u_train = np.reshape(u[:-1,-21:-1,-21:-1],(-1,1))\n",
    "\n",
    "print(np.shape(x_train))\n",
    "print(np.shape(lace_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-14 10:00:15.302218: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-14 10:00:22.257118: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-14 10:00:22.289561: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 1), dtype=float32, numpy=\n",
       "array([[-0.09606534],\n",
       "       [-1.159835  ],\n",
       "       [-1.5355389 ],\n",
       "       [-1.8860911 ]], dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear Regression\n",
    "from tensorflow.keras.layers import Layer, Dense\n",
    "from tensorflow.keras.layers import Input, Add, Multiply, Lambda, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.keras.backend.set_floatx('float64')\n",
    "\n",
    "linear_target_dim = 4\n",
    "output_dim = 1\n",
    "inputs = Input((linear_target_dim,))\n",
    "layer_linear = Dense(output_dim, use_bias=False)\n",
    "outputs = layer_linear(inputs)\n",
    "model_linear = Model(inputs=inputs, outputs=outputs)\n",
    "tf.cast(model_linear.trainable_weights[0],tf.float32)-tf.ones((linear_target_dim, output_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Koopman_DL\n",
    "from tensorflow.keras.layers import Layer, Dense\n",
    "from tensorflow.keras.layers import Input, Add, Multiply, Lambda, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.keras.backend.set_floatx('float64')\n",
    "\n",
    "class DicNN(Layer):\n",
    "    \"\"\"\n",
    "    Trainable disctionries\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, layer_sizes=[64, 64], n_psi_train=22, **kwargs):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            layer_sizes (list, optional): Number of unit of hidden layer, activation = 'tanh'. Defaults to [64, 64].\n",
    "            n_psi_train (int, optional): Number of unit of output layer. Defaults to 22.\n",
    "        \"\"\"\n",
    "        super(DicNN, self).__init__(**kwargs)\n",
    "        self.layer_sizes = layer_sizes\n",
    "        self.input_layer = Dense(self.layer_sizes[0], name='Dic_input', use_bias=False)\n",
    "        self.hidden_layers = [Dense(layer_sizes[i], activation='tanh', name='Dic_hidden_%d'%i) for i in range(len(layer_sizes))]        \n",
    "        self.output_layer = Dense(n_psi_train, name='Dic_output')\n",
    "        self.n_psi_train = n_psi_train\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        psi_x_train = self.input_layer(inputs)\n",
    "        for layer in self.hidden_layers:\n",
    "            psi_x_train = psi_x_train + layer(psi_x_train)\n",
    "        outputs = self.output_layer(psi_x_train)\n",
    "        return outputs\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super(DicNN, self).get_config()\n",
    "        config.update({\n",
    "            'layer_sizes': self.layer_sizes,\n",
    "            'n_psi_train': self.n_psi_train\n",
    "        })\n",
    "        return config\n",
    "\n",
    "class PsiNN(Layer):\n",
    "    \"\"\"Concatenate constant, data and trainable dictionaries together as [1, data, DicNN]\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        dic_trainable=DicNN,\n",
    "        layer_sizes=[64,64],\n",
    "        n_psi_train=22,\n",
    "        **kwargs):\n",
    "        super(PsiNN, self).__init__(**kwargs)\n",
    "        self.layer_sizes = layer_sizes\n",
    "        self.dic_trainable = dic_trainable\n",
    "        self.n_dic_customized = n_psi_train\n",
    "        self.dicNN = self.dic_trainable(\n",
    "            layer_sizes=self.layer_sizes,\n",
    "            n_psi_train=self.n_dic_customized)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        constant = tf.ones_like(tf.slice(inputs, [0, 0], [-1, 1]))\n",
    "        psi_x_train = self.dicNN(inputs)\n",
    "        outputs = Concatenate()([constant, inputs, psi_x_train])\n",
    "        return outputs\n",
    "    \n",
    "    def generate_B(self, inputs):\n",
    "        target_dim = inputs.shape[-1]\n",
    "        self.basis_func_number = self.n_dic_customized + target_dim + 1\n",
    "        # Form B matrix\n",
    "        self.B = np.zeros((self.basis_func_number, target_dim))\n",
    "        for i in range(0, target_dim):\n",
    "            self.B[i + 1][i] = 1\n",
    "        return self.B\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(PsiNN, self).get_config()\n",
    "        config.update({\n",
    "            'dic_trainable': self.dic_trainable,\n",
    "            'layer_sizes': self.layer_sizes,\n",
    "            'n_psi_train': self.n_dic_customized\n",
    "        })\n",
    "        return config\n",
    "    \n",
    "class KNN(Layer):\n",
    "    def __init__(self, n_K=27, layer_sizes=[32, 32], **kwargs):\n",
    "        self.layer_sizes = layer_sizes\n",
    "        self.n_K = n_K\n",
    "        self.input_layer = Dense(self.layer_sizes[0], name='K_input')\n",
    "        self.hidden_layers = [Dense(layer_sizes[i], activation='tanh', name='K_hidden_%d'%i) for i in range(len(layer_sizes))]\n",
    "        self.output_layer = Dense(self.n_K**2, name='K_output')\n",
    "        \n",
    "    def call(self, inputs_u):\n",
    "        K = self.input_layer(inputs_u)\n",
    "        for layer in self.hidden_layers:\n",
    "            K = K + layer(K)\n",
    "#         outputs = K\n",
    "        outputs = self.output_layer(K)\n",
    "#         return outputs\n",
    "        return tf.reshape(outputs,(-1,self.n_K,self.n_K))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dim = 4\n",
    "u_dim = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = PsiNN()\n",
    "knn = KNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Model\n",
    "inputs_x = Input((target_dim,))\n",
    "inputs_y = Input((target_dim,))\n",
    "inputs_u = Input((u_dim,))\n",
    "        \n",
    "model_psi = Model(inputs=inputs_x, outputs=dic.call(inputs_x))\n",
    "psi_x = model_psi(inputs_x)\n",
    "psi_y = model_psi(inputs_y)\n",
    "        \n",
    "model_k = Model(inputs=inputs_u,outputs=knn.call(inputs_u))\n",
    "# outputs = tf.matmul(psi_x,model_k(inputs_u)) - psi_y\n",
    "psi_x = tf.expand_dims(psi_x, 1)\n",
    "psi_y = tf.expand_dims(psi_y, 1)\n",
    "outputs = tf.matmul(psi_x,model_k(inputs_u))-psi_y\n",
    "outputs = tf.reshape(outputs,(tf.shape(psi_x)[0],-1))\n",
    "model_KoopmanDL = Model(inputs=[inputs_x, inputs_y, inputs_u], outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-train\n",
    "lr = 0.01\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "model_KoopmanDL.compile(optimizer=opt, loss='mse')\n",
    "model_linear.compile(optimizer=opt, loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1238/1238 [==============================] - 6s 4ms/step - loss: 1.0022\n",
      "Epoch 2/2\n",
      "1238/1238 [==============================] - 4s 3ms/step - loss: 0.0120\n",
      "Epoch 1/10\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 251.0114\n",
      "Epoch 2/10\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.0052\n",
      "Epoch 3/10\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.0529\n",
      "Epoch 4/10\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.0973\n",
      "Epoch 5/10\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.0921\n",
      "Epoch 6/10\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.0670\n",
      "Epoch 7/10\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.0576\n",
      "Epoch 8/10\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.0665\n",
      "Epoch 9/10\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 135.8618\n",
      "Epoch 10/10\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.0402\n",
      "Epoch 1/2\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.6876\n",
      "Epoch 2/2\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.9310\n",
      "Epoch 1/10\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 2.8583\n",
      "Epoch 2/10\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.0960\n",
      "Epoch 3/10\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.1556\n",
      "Epoch 4/10\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.0912\n",
      "Epoch 5/10\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.0846\n",
      "Epoch 6/10\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.0721\n",
      "Epoch 7/10\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 55.0950\n",
      "Epoch 8/10\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.0117\n",
      "Epoch 9/10\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.0032\n",
      "Epoch 10/10\n",
      "1238/1238 [==============================] - 6s 5ms/step - loss: 0.1158\n",
      "Epoch 1/2\n",
      "1238/1238 [==============================] - 6s 5ms/step - loss: 0.1108\n",
      "Epoch 2/2\n",
      "1238/1238 [==============================] - 6s 5ms/step - loss: 0.0732\n",
      "Epoch 1/10\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 18.8502\n",
      "Epoch 2/10\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.1152\n",
      "Epoch 3/10\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.1117\n",
      "Epoch 4/10\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.0944\n",
      "Epoch 5/10\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.0631\n",
      "Epoch 6/10\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.0439\n",
      "Epoch 7/10\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 8.6771\n",
      "Epoch 8/10\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.0022\n",
      "Epoch 9/10\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.0044\n",
      "Epoch 10/10\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.0150\n",
      "Epoch 1/2\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.0221\n",
      "Epoch 2/2\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 8.2260\n",
      "Epoch 1/10\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.8351\n",
      "Epoch 2/10\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.0048\n",
      "Epoch 3/10\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.0307\n",
      "Epoch 4/10\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.0257\n",
      "Epoch 5/10\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.0257\n",
      "Epoch 6/10\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.0240\n",
      "Epoch 7/10\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.0197\n",
      "Epoch 8/10\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.0207\n",
      "Epoch 9/10\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 6.3757\n",
      "Epoch 10/10\n",
      "1238/1238 [==============================] - 7s 5ms/step - loss: 0.0038\n",
      "Epoch 1/2\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.0030\n",
      "Epoch 2/2\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.0195\n",
      "Epoch 1/10\n",
      "1238/1238 [==============================] - 6s 4ms/step - loss: 0.9560\n",
      "Epoch 2/10\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.0245\n",
      "Epoch 3/10\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.0210\n",
      "Epoch 4/10\n",
      "1238/1238 [==============================] - 4s 4ms/step - loss: 0.0183\n",
      "Epoch 5/10\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.0169\n",
      "Epoch 6/10\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 2.6172\n",
      "Epoch 7/10\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.0215\n",
      "Epoch 8/10\n",
      "1238/1238 [==============================] - 4s 4ms/step - loss: 0.0193\n",
      "Epoch 9/10\n",
      "1238/1238 [==============================] - 4s 4ms/step - loss: 0.0233\n",
      "Epoch 10/10\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.0201\n"
     ]
    }
   ],
   "source": [
    "iters = 5\n",
    "epochs = [2,10]\n",
    "zeros_data_y_train = tf.zeros_like(dic.call(y_train))\n",
    "for i in range(iters):\n",
    "    model_k.trainable = True\n",
    "    model_psi.trainable = False\n",
    "#     print(model_KoopmanDL.trainable_weights)\n",
    "    model_KoopmanDL.fit([x_train, y_train, u_train], zeros_data_y_train, epochs=epochs[0])\n",
    "    model_k.trainable = False\n",
    "    model_psi.trainable = True\n",
    "#     print(model_KoopmanDL.trainable_weights)\n",
    "    model_KoopmanDL.fit([x_train, y_train, u_train], zeros_data_y_train, epochs=epochs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_k.trainable = False\n",
    "# model_psi.trainable = False\n",
    "# model_KoopmanDL.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_v_koopman(model_psi, model_k, x_train, u_train):\n",
    "    psi_x = model_psi(x_train)\n",
    "    psi_x = tf.expand_dims(psi_x, 1)\n",
    "    outputs = tf.matmul(psi_x,model_k(u_train))\n",
    "    outputs = tf.reshape(outputs,(tf.shape(psi_x)[0],-1))\n",
    "    return outputs[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_linear_weight(x,y):\n",
    "    y = tf.expand_dims(y, 1)\n",
    "    A = tf.matmul(tf.transpose(x),x)\n",
    "    b = tf.matmul(tf.transpose(x),y)\n",
    "    w = tf.matmul(tf.linalg.inv(A),b)\n",
    "    y_pred = tf.matmul(x,w)\n",
    "    return w, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[299.63221681 299.63221681 299.63221681 ... 276.38290105 276.37993507\n",
      " 276.37815033], shape=(39600,), dtype=float64)\n",
      "tf.Tensor(\n",
      "[[ 0.23770637]\n",
      " [-0.24250945]\n",
      " [ 1.12667662]\n",
      " [25.58069629]], shape=(4, 1), dtype=float64)\n",
      "Epoch 1/20\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 456.8294\n",
      "Epoch 2/20\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.1892\n",
      "Epoch 3/20\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 1.1723\n",
      "Epoch 4/20\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 1.9447\n",
      "Epoch 5/20\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.9378\n",
      "Epoch 6/20\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 1.1557\n",
      "Epoch 7/20\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.4560\n",
      "Epoch 8/20\n",
      "1238/1238 [==============================] - 6s 5ms/step - loss: 0.4723\n",
      "Epoch 9/20\n",
      "1238/1238 [==============================] - 6s 5ms/step - loss: 56.5607\n",
      "Epoch 10/20\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.0918\n",
      "Epoch 11/20\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.3603\n",
      "Epoch 12/20\n",
      "1238/1238 [==============================] - 6s 5ms/step - loss: 0.2614\n",
      "Epoch 13/20\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.5099\n",
      "Epoch 14/20\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.3671\n",
      "Epoch 15/20\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 16.4707\n",
      "Epoch 16/20\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.0907\n",
      "Epoch 17/20\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.2773\n",
      "Epoch 18/20\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.2188\n",
      "Epoch 19/20\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 4.6132\n",
      "Epoch 20/20\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.1021\n",
      "tf.Tensor(\n",
      "[[  1.39365395]\n",
      " [ -1.4217908 ]\n",
      " [  6.71368008]\n",
      " [149.82146295]], shape=(4, 1), dtype=float64)\n",
      "Epoch 1/20\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.1589\n",
      "Epoch 2/20\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.2287\n",
      "Epoch 3/20\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 16.4739\n",
      "Epoch 4/20\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.1738\n",
      "Epoch 5/20\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.4477\n",
      "Epoch 6/20\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.0677\n",
      "Epoch 7/20\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.3735\n",
      "Epoch 8/20\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.1706\n",
      "Epoch 9/20\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.1700\n",
      "Epoch 10/20\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 139.3029\n",
      "Epoch 11/20\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.1128\n",
      "Epoch 12/20\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.2586\n",
      "Epoch 13/20\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 1.2568\n",
      "Epoch 14/20\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.2882\n",
      "Epoch 15/20\n",
      "1238/1238 [==============================] - 6s 5ms/step - loss: 0.4220\n",
      "Epoch 16/20\n",
      "1238/1238 [==============================] - 6s 5ms/step - loss: 0.4826\n",
      "Epoch 17/20\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 59.4092\n",
      "Epoch 18/20\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.6167\n",
      "Epoch 19/20\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.6878\n",
      "Epoch 20/20\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.4091\n",
      "tf.Tensor(\n",
      "[[  1.40610229]\n",
      " [ -1.43449147]\n",
      " [  6.75380179]\n",
      " [151.17867124]], shape=(4, 1), dtype=float64)\n",
      "Epoch 1/20\n",
      "1238/1238 [==============================] - 4s 4ms/step - loss: 0.1939\n",
      "Epoch 2/20\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.3070\n",
      "Epoch 3/20\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.2423\n",
      "Epoch 4/20\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.2499\n",
      "Epoch 5/20\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 28.6674\n",
      "Epoch 6/20\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.0082\n",
      "Epoch 7/20\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.1945\n",
      "Epoch 8/20\n",
      "1238/1238 [==============================] - 6s 5ms/step - loss: 0.2899\n",
      "Epoch 9/20\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.3249\n",
      "Epoch 10/20\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.3743\n",
      "Epoch 11/20\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.1622\n",
      "Epoch 12/20\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.1001\n",
      "Epoch 13/20\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 114.7041\n",
      "Epoch 14/20\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.6786\n",
      "Epoch 15/20\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.2856\n",
      "Epoch 16/20\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 1.2242\n",
      "Epoch 17/20\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.2500\n",
      "Epoch 18/20\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.3881\n",
      "Epoch 19/20\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.2189\n",
      "Epoch 20/20\n",
      "1238/1238 [==============================] - 7s 5ms/step - loss: 150.5162\n",
      "tf.Tensor(\n",
      "[[  1.36008259]\n",
      " [ -1.38755406]\n",
      " [  6.36781403]\n",
      " [146.39222215]], shape=(4, 1), dtype=float64)\n",
      "Epoch 1/20\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 43.6073\n",
      "Epoch 2/20\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 1.9344\n",
      "Epoch 3/20\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.1269\n",
      "Epoch 4/20\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 0.5413\n",
      "Epoch 5/20\n",
      "1238/1238 [==============================] - 4s 4ms/step - loss: 0.5614\n",
      "Epoch 6/20\n",
      "1238/1238 [==============================] - 4s 4ms/step - loss: 0.3416\n",
      "Epoch 7/20\n",
      "1238/1238 [==============================] - 5s 4ms/step - loss: 219.3249\n",
      "Epoch 8/20\n",
      " 628/1238 [==============>...............] - ETA: 2s - loss: 0.1039"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 29\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(linear_weight)\n\u001b[1;32m     28\u001b[0m y_train[:,\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m y_v\u001b[38;5;241m-\u001b[39mtf\u001b[38;5;241m.\u001b[39mreshape(v_linear, (\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 29\u001b[0m \u001b[43mmodel_KoopmanDL\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu_train\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzeros_data_y_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkoopman_epochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m v_koopman \u001b[38;5;241m=\u001b[39m predict_v_koopman(model_psi, model_k, x_train, u_train)\n",
      "File \u001b[0;32m~/anaconda3/envs/koopman/lib/python3.8/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/koopman/lib/python3.8/site-packages/keras/engine/training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1562\u001b[0m ):\n\u001b[1;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/envs/koopman/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/koopman/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/koopman/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/envs/koopman/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2494\u001b[0m   (graph_function,\n\u001b[1;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/koopman/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1865\u001b[0m     args,\n\u001b[1;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1867\u001b[0m     executing_eagerly)\n\u001b[1;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/koopman/lib/python3.8/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/anaconda3/envs/koopman/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Hybrid Koopman\n",
    "model_k.trainable = True\n",
    "model_psi.trainable = False\n",
    "err = 1e-8\n",
    "linear_epochs = 10\n",
    "koopman_epochs = 20\n",
    "\n",
    "# Linear Weight\n",
    "linear_weight = tf.cast(tf.zeros(linear_target_dim),tf.float64)\n",
    "\n",
    "# Set initial v_koopman\n",
    "v_koopman = predict_v_koopman(model_psi, model_k, x_train, u_train)\n",
    "psi_x = model_psi(x_train)\n",
    "psi_x = tf.expand_dims(psi_x, 1)\n",
    "outputs = tf.matmul(psi_x,model_k(u_train))\n",
    "outputs = tf.reshape(outputs,(tf.shape(psi_x)[0],-1))\n",
    "y_train = y_train-x_train\n",
    "y_v = np.reshape(y_train[:,0], (1,-1))[0]\n",
    "y_v = tf.convert_to_tensor(y_v, tf.float64)\n",
    "print(outputs[:,1])\n",
    "mu_pred = tf.cast(1e8*tf.ones((linear_target_dim, output_dim)),tf.float64)\n",
    "# print(tf.shape(tf.reshape(v_linear, (1,-1))[0]))\n",
    "while (tf.norm(mu_pred - linear_weight)>err):\n",
    "    mu_pred = linear_weight\n",
    "    y_linear = y_v-v_koopman\n",
    "    linear_weight, v_linear = compute_linear_weight(lace_train,y_linear)\n",
    "    print(linear_weight)\n",
    "    y_train[:,0] = y_v-tf.reshape(v_linear, (1,-1))[0]\n",
    "    model_KoopmanDL.fit([y_train, y_train, u_train], zeros_data_y_train, epochs=koopman_epochs)\n",
    "    v_koopman = predict_v_koopman(model_psi, model_k, x_train, u_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Koopman_DL\n",
    "# from tensorflow.keras.layers import Layer, Dense\n",
    "# from tensorflow.keras.layers import Input, Add, Multiply, Lambda, Concatenate\n",
    "# from tensorflow.keras.models import Model\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "# import numpy as np\n",
    "# import tensorflow as tf\n",
    "# tf.keras.backend.set_floatx('float64')\n",
    "\n",
    "# class DicNN(Layer):\n",
    "#     \"\"\"\n",
    "#     Trainable disctionries\n",
    "#     \"\"\"\n",
    "    \n",
    "#     def __init__(self, layer_sizes=[64, 64], n_psi_train=22,trainable_para=True, **kwargs):\n",
    "#         \"\"\"_summary_\n",
    "\n",
    "#         Args:\n",
    "#             layer_sizes (list, optional): Number of unit of hidden layer, activation = 'tanh'. Defaults to [64, 64].\n",
    "#             n_psi_train (int, optional): Number of unit of output layer. Defaults to 22.\n",
    "#         \"\"\"\n",
    "#         super(DicNN, self).__init__(**kwargs)\n",
    "#         self.layer_sizes = layer_sizes\n",
    "#         self.input_layer = Dense(self.layer_sizes[0], name='Dic_input',trainable = trainable_para, use_bias=False)\n",
    "#         self.hidden_layers = [Dense(layer_sizes[i], activation='tanh', name='Dic_hidden_%d'%i, trainable = trainable_para) for i in len(layer_sizes)]        \n",
    "#         self.output_layer = Dense(n_psi_train, name='Dic_output',trainable = trainable_para)\n",
    "#         self.n_psi_train = n_psi_train\n",
    "        \n",
    "#     def call(self, inputs):\n",
    "#         psi_x_train = self.input_layer(inputs)\n",
    "#         for layer in self.hidden_layers:\n",
    "#             psi_x_train = psi_x_train + layer(psi_x_train)\n",
    "#         outputs = self.output_layer(psi_x_train)\n",
    "#         return outputs\n",
    "    \n",
    "#     def get_config(self):\n",
    "#         config = super(DicNN, self).get_config()\n",
    "#         config.update({\n",
    "#             'layer_sizes': self.layer_sizes,\n",
    "#             'n_psi_train': self.n_psi_train\n",
    "#         })\n",
    "#         return config\n",
    "\n",
    "# class PsiNN(Layer):\n",
    "#     \"\"\"Concatenate constant, data and trainable dictionaries together as [1, data, DicNN]\n",
    "\n",
    "#     \"\"\"\n",
    "    \n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         dic_trainable=DicNN,\n",
    "#         layer_sizes=[64,64],\n",
    "#         n_psi_train=22,\n",
    "#         trainable_para=True,\n",
    "#         **kwargs):\n",
    "#         super(PsiNN, self).__init__(**kwargs)\n",
    "#         self.layer_sizes = layer_sizes\n",
    "#         self.dic_trainable = dic_trainable\n",
    "#         self.trainable_para = trainable_para\n",
    "#         self.n_dic_customized = n_psi_train\n",
    "#         self.dicNN = self.dic_trainable(\n",
    "#             layer_sizes=self.layer_sizes,\n",
    "#             n_psi_train=self.n_dic_customized,\n",
    "#             trainable_para=self.trainable_para)\n",
    "    \n",
    "#     def call(self, inputs):\n",
    "#         constant = tf.ones_like(tf.slice(inputs, [0, 0], [-1, 1]))\n",
    "#         psi_x_train = self.dicNN(inputs)\n",
    "#         outputs = Concatenate()([constant, inputs, psi_x_train])\n",
    "#         return outputs\n",
    "    \n",
    "#     def generate_B(self, inputs):\n",
    "#         target_dim = inputs.shape[-1]\n",
    "#         self.basis_func_number = self.n_dic_customized + target_dim + 1\n",
    "#         # Form B matrix\n",
    "#         self.B = np.zeros((self.basis_func_number, target_dim))\n",
    "#         for i in range(0, target_dim):\n",
    "#             self.B[i + 1][i] = 1\n",
    "#         return self.B\n",
    "\n",
    "#     def get_config(self):\n",
    "#         config = super(PsiNN, self).get_config()\n",
    "#         config.update({\n",
    "#             'dic_trainable': self.dic_trainable,\n",
    "#             'layer_sizes': self.layer_sizes,\n",
    "#             'n_psi_train': self.n_dic_customized\n",
    "#         })\n",
    "#         return config\n",
    "    \n",
    "# class KNN(Layer):\n",
    "#     def __init__(self, layer_sizes=[32, 32], n_K, trainable_para = True, **kwargs):\n",
    "#         self.layer_sizes = layer_sizes\n",
    "#         self.input_layer = Dense(self.layer_sizes[0], use_bias=False, name='K_input',  trainable=trainable_para)\n",
    "#         self.hidden_layers = [Dense(layer_sizes[i], activation='tanh', name='K_hidden_%d'%i, trainable = trainable_para) for i in len(layer_sizes)]\n",
    "#         self.output_layer = Dense(n_K**2, name='K_output', trainable = trainable_para)\n",
    "#         self.n_K = n_K\n",
    "        \n",
    "#     def call(self, inputs_u, inputs_x):\n",
    "#         K = self.input_layer(inputs_u)\n",
    "#         for layer in self.hidden_layers:\n",
    "#             K = K + layer(K)\n",
    "#         outputs = self.output_layer(K)\n",
    "#         return inputs_x@np.reshape(outputs,(self.n_K,-1))\n",
    "    \n",
    "    \n",
    "# class KoopmanDLSolver(object):\n",
    "#     \"\"\"\n",
    "#     Koopman model with dictionray\n",
    "#     \"\"\"\n",
    "    \n",
    "#     def __init__(self, dic=PsiNN, k=KNN, target_dim, u_dim, reg=0.0):\n",
    "#         \"\"\"Initializer\n",
    "\n",
    "#         :param dic: dictionary\n",
    "#         :type dic: class\n",
    "#         :param target_dim: dimension of the variable of the equation\n",
    "#         :type target_dim: int\n",
    "#         :param reg: the regularization parameter when computing K, defaults to 0.0\n",
    "#         :type reg: float, optional\n",
    "#         \"\"\"\n",
    "# #         self.dic_train = dic_train # dictionary class\n",
    "# #         self.dic_func = dic_train.call # dictionary functions\n",
    "#         self.target_dim = target_dim # x,y dimension\n",
    "#         self.dic_train = dic(dic_trainable=DicNN,layer_sizes=[64,64],n_psi_train=22,trainable_para=True)\n",
    "#         self.dic_fix =  dic(dic_trainable=DicNN,layer_sizes=[64,64],n_psi_train=22,trainable_para=False)\n",
    "#         self.k_train = k(layer_sizes=[32, 32], n_K=1+self.target_dim+22, trainable_para = True)\n",
    "#         self.k_fix = k(layer_sizes=[32, 32], n_K=1+self.target_dim+22, trainable_para = True)\n",
    "#         self.u_dim = u_dim # u_dimension\n",
    "#         self.reg = reg\n",
    "# #         self.KNN = KNN\n",
    "# #         self.KNN_func = KNN.call\n",
    "        \n",
    "#     def build_model_psi(self):\n",
    "#         \"\"\"\n",
    "#         Build model with trainable dictionary\n",
    "#         The loss function is ||Psi(y) - K Psi(x)||^2 .\n",
    "#         \"\"\"\n",
    "        \n",
    "#         inputs_x = Input((self.target_dim,))\n",
    "#         inputs_y = Input((self.target_dim,))\n",
    "#         inputs_u = Input((self.u_dim,))\n",
    "        \n",
    "#         # model_psi\n",
    "#         psi_x = self.dic_train.call(inputs_x)\n",
    "#         psi_y = self.dic_train.call(inputs_y)\n",
    "        \n",
    "#         psi_next = self.k_fix.call(inputs_u, psi_x)\n",
    "        \n",
    "#         outputs = psi_next - psi_y\n",
    "#         model_psi = Model(inputs=[inputs_x, inputs_y, inputs_u], outputs=outputs)\n",
    "#         return model_psi\n",
    "    \n",
    "#     def build_model_k(self):\n",
    "#         inputs_x = Input((self.target_dim,))\n",
    "#         inputs_y = Input((self.target_dim,))\n",
    "#         inputs_u = Input((self.u_dim,))\n",
    "#         # model_k\n",
    "#         psi_x = self.dic_fix.call(inputs_x)\n",
    "#         psi_y = self.dic_fix.call(inputs_y)\n",
    "        \n",
    "#         psi_next = self.k_train.call(inputs_u, psi_x)\n",
    "        \n",
    "#         outputs = psi_next - psi_y\n",
    "#         model_k = Model(inputs=[inputs_x, inputs_y, inputs_u], outputs=outputs)\n",
    "        \n",
    "#         return model_k\n",
    "\n",
    "# #     def train_psi(self, model, epochs):\n",
    "# #         \"\"\"Train the trainable part of the dictionary\n",
    "\n",
    "# #         :param model: koopman model\n",
    "# #         :type model: model\n",
    "# #         :param epochs: the number of training epochs before computing K for each inner training epoch\n",
    "# #         :type epochs: int\n",
    "# #         :return: history\n",
    "# #         :rtype: history callback object\n",
    "# #         \"\"\"\n",
    "# #         history = model.fit(\n",
    "# #             x=self.data_train,\n",
    "# #             y=self.zeros_data_y_train,\n",
    "# #             epochs=epochs,\n",
    "# #             validation_data=(\n",
    "# #                 self.data_valid,\n",
    "# #                 self.zeros_data_y_valid),\n",
    "# #             batch_size=self.batch_size,\n",
    "# #             verbose=1)\n",
    "# #         return history\n",
    "#     def separate_data(self, data_train):\n",
    "#         return data_train[0], data_train[1], data_train[2]\n",
    "        \n",
    "#     def double_train(self, data_train, model_k, model_psi, epochs, steps, batch_size, lr):\n",
    "#         self.data_train = data_train\n",
    "#         self.data_x_train, self.data_y_train, self.data_u_train = self.separate_data(self.data_train)\n",
    "\n",
    "#         self.zeros_data_y_train = tf.zeros_like(\n",
    "#             self.dic_func(self.data_y_train))\n",
    "        \n",
    "#         self.batch_size = batch_size\n",
    "\n",
    "#         # Compile the Koopman DL model\n",
    "#         opt = Adam(lr)\n",
    "#         self.model_k.compile(optimizer=opt, loss='mse')\n",
    "\n",
    "#         # Training Loop\n",
    "#         losses = []\n",
    "#         for i in range(epochs):\n",
    "#             # One step for computing K\n",
    "#             self.K = self.compute_K(self.dic_func,\n",
    "#                                     self.data_x_train,\n",
    "#                                     self.data_y_train,\n",
    "#                                     self.reg)\n",
    "#             self.model.get_layer('Layer_K').weights[0].assign(self.K)\n",
    "\n",
    "#             # Two steps for training PsiNN\n",
    "#             self.history = self.train_psi(self.model, epochs=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "9ed6572b4823cf05429c704e5290e1de40e3298c18e495d05bb241501b447552"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
